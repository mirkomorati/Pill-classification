{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ftplib import FTP\n",
    "import utils\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "\n",
    "server='lhcftp.nlm.nih.gov'\n",
    "dirs_from_to=(1, 110)\n",
    "source_dirs=['Open-Access-Datasets/Pills/PillProjectDisc' + str(x) +'/images' for x in range(dirs_from_to[0], dirs_from_to[1]+1)]\n",
    "\n",
    "dest_base_dir=Path('Dataset')\n",
    "\n",
    "with FTP(server) as ftp:\n",
    "    print('Login into {}'.format(server))\n",
    "    ftp.login()\n",
    "\n",
    "    base_dir = ftp.pwd()\n",
    "    \n",
    "    for idx, source_dir in enumerate(source_dirs):\n",
    "        ftp.cwd(base_dir)\n",
    "        ftp.cwd(source_dir)\n",
    "        \n",
    "        dest_dir = dest_base_dir / str(idx)\n",
    "        \n",
    "        dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        print('Current woring directory:', ftp.pwd())\n",
    "        print('Downloading tmp xml')\n",
    "        filename = 'images.xml'\n",
    "        dest_file = dest_dir / filename\n",
    "        with open(dest_file, 'wb') as f:\n",
    "            ftp.retrbinary('RETR ' + filename, f.write)\n",
    "\n",
    "        tree = ET.parse(dest_file)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        se = list(root)[0]\n",
    "        \n",
    "        print('Filtering xml (' + str(len(list(se))) + ' images)')\n",
    "        images = []\n",
    "        for e in list(se):\n",
    "            layout = e.find('Layout')\n",
    "            shadow = e.find('RatingShadow')\n",
    "            if (layout is not None and layout.text == \"MC_C3PI_REFERENCE_SEG_V1.6\") or \\\n",
    "               (shadow is not None and shadow.text == 'Soft'):\n",
    "                images.append(e.find('File').find('Name').text)\n",
    "            else:\n",
    "                se.remove(e)\n",
    "        \n",
    "        print('saving xml in:', dest_file)\n",
    "        tree.write(dest_file)\n",
    "        \n",
    "        print(\"final images:\", len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# in this part I check if there are more images with the same type of drug \n",
    "dirs = [x for x in dest_base_dir.iterdir() if x.is_dir()]\n",
    "\n",
    "ids = dict()\n",
    "\n",
    "expected_size = 0\n",
    "\n",
    "for d in dirs:\n",
    "    try:\n",
    "        tree = ET.parse(d / 'images.xml')\n",
    "    except ET.ParseError:\n",
    "        print('Parse error on {}'.format(d/'images.xml'))\n",
    "        continue\n",
    "    se = list(tree.getroot())[0]\n",
    "    \n",
    "    for e in list(se):\n",
    "        expected_size += int(e.find('File').find('Size').text)\n",
    "        \n",
    "        # i = e.find('ProprietaryName').text.lower()\n",
    "        # i = e.find('NDC11').text[5:9]\n",
    "        i = e.find('NDC9').text\n",
    "        if i not in ids:\n",
    "            ids[i] = []\n",
    "        ids[i].append(e.find('File').find('Name').text) \n",
    "\n",
    "sizes = dict()\n",
    "\n",
    "for k, e in ids.items():\n",
    "    if len(e) not in sizes:\n",
    "        sizes[len(e)] = []\n",
    "    sizes[len(e)].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted_sizes = list(sizes.keys())\n",
    "sorted_sizes.sort(reverse=True)\n",
    "\n",
    "total_ids = 0\n",
    "total_images = 0\n",
    "for k in sorted_sizes:\n",
    "    print('{:4} ids with {:4} images'.format(len(sizes[k]), k))\n",
    "    total_ids += len(sizes[k])\n",
    "    total_images += len(sizes[k]) * k\n",
    "    \n",
    "print('Total ids: {}'.format(total_ids))\n",
    "print('Total images: {}'.format(total_images))\n",
    "\n",
    "print(utils.bytes2human(expected_size), 'will be needed to download all the images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ids_to_download = sizes[10]\n",
    "download_imgs = True\n",
    "\n",
    "with FTP(server) as ftp:\n",
    "    print('Login into {}'.format(server))\n",
    "    ftp.login()\n",
    "\n",
    "    base_dir = ftp.pwd()\n",
    "    \n",
    "    for idx, source_dir in enumerate(source_dirs):\n",
    "        ftp.cwd(base_dir)\n",
    "        ftp.cwd(source_dir)\n",
    "        \n",
    "        dest_dir = dest_base_dir / str(idx)\n",
    "        \n",
    "        print(dest_dir)\n",
    "        \n",
    "        try:\n",
    "            tree = ET.parse(dest_dir / 'images.xml')\n",
    "        except ET.ParseError:\n",
    "            print('Parse error on {}'.format(dest_dir / 'images.xml'))\n",
    "            continue\n",
    "        se = list(tree.getroot())[0]\n",
    "        \n",
    "        images = []\n",
    "        \n",
    "        for e in list(se):\n",
    "            ndc = e.find('NDC9').text\n",
    "            if ndc in ids_to_download:\n",
    "                images.append(e.find('File').find('Name').text)\n",
    "        \n",
    "        # downloading\n",
    "        if download_imgs:\n",
    "            for i, img in enumerate(images):\n",
    "                dest_file = dest_dir / img\n",
    "                if (dest_file).exists():\n",
    "                    print(img, 'already downloaded!')\n",
    "                    continue\n",
    "                with open(dest_file, 'wb') as f:\n",
    "                    print('\\rDownloading {:3}/{}'.format(i + 1, len(images)), end='')\n",
    "                    ftp.retrbinary('RETR ' + img, f.write)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging dir 110/110Saving xml\n"
     ]
    }
   ],
   "source": [
    "# Merge in one dir\n",
    "\n",
    "import shutil\n",
    "\n",
    "merge_dir = dest_base_dir / 'merge'\n",
    "\n",
    "merge_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "merge_xml = ET.Element('MedicosConsultants')\n",
    "ET.SubElement(merge_xml, 'ImageExport')\n",
    "\n",
    "for i, d in enumerate(dirs):\n",
    "    print('\\rMerging dir {:3}/{}'.format(i + 1, len(dirs)), end='')\n",
    "    imgs = [x.name for x in d.iterdir() if x.suffix != '.xml']\n",
    "    \n",
    "    tree = ET.parse(d / 'images.xml')\n",
    "    \n",
    "    se = list(tree.getroot())[0]\n",
    "    \n",
    "    for e in list(se):\n",
    "        name = e.find('File').find('Name').text\n",
    "        if name in imgs:\n",
    "            merge_xml[0].append(e)\n",
    "    \n",
    "    for img in imgs:\n",
    "        shutil.move(str(d / img), str(merge_dir))\n",
    "\n",
    "print('\\nSaving xml')\n",
    "ET.ElementTree(merge_xml).write(merge_dir / 'images.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "\n",
    "shas = list(map(lambda x : x.text, merge_xml.findall('.//Sha1')))\n",
    "\n",
    "def list_duplicates(seq):\n",
    "  seen = set()\n",
    "  seen_add = seen.add\n",
    "  # adds all elements it doesn't know yet to seen and all other to seen_twice\n",
    "  seen_twice = set( x for x in seq if x in seen or seen_add(x) )\n",
    "  # turn the set into a list (as requested)\n",
    "  return list( seen_twice )\n",
    "\n",
    "print(list_duplicates(shas))\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "d =  Counter(shas)\n",
    "res = [k for k, v in d.items() if v > 1]\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
